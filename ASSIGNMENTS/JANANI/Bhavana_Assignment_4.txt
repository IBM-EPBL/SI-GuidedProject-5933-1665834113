{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9f2d821a",
      "metadata": {
        "id": "9f2d821a"
      },
      "source": [
        "## 1. Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "365de96e",
      "metadata": {
        "id": "365de96e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f5a8875d",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f5a8875d",
        "outputId": "0cbb8953-3d64-43af-a636-675963b3f451"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'archive.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df = 'archive.zip'\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eadc80ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "eadc80ab",
        "outputId": "bd8c46f7-c483-494e-8f3a-74edda761a5c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    result = chardet.detect(rawdata.read(100000))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ],
      "source": [
        "import chardet\n",
        "      with open(df, 'rb') as rawdata:\n",
        "    result = chardet.detect(rawdata.read(100000))\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d983b89b",
      "metadata": {
        "id": "d983b89b"
      },
      "source": [
        "## 2. Read The Dataset And Do Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc76b2b",
      "metadata": {
        "id": "0fc76b2b"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(df,encoding='ISO-8859-1')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "95c84d3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "95c84d3b",
        "outputId": "c5ce5b5d-24a4-43fb-eb34-e538bf9dfe6c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c3d483a1c074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976b0131",
      "metadata": {
        "id": "976b0131"
      },
      "outputs": [],
      "source": [
        "#Drop the unnamed columns\n",
        "data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269e5fa5",
      "metadata": {
        "id": "269e5fa5"
      },
      "outputs": [],
      "source": [
        "#Print the number of rows in the dataset\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba95d70",
      "metadata": {
        "id": "bba95d70"
      },
      "outputs": [],
      "source": [
        "#Get the summary statistics of the dataset\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88b2d0d4",
      "metadata": {
        "id": "88b2d0d4"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "857f882c",
      "metadata": {
        "id": "857f882c"
      },
      "outputs": [],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "614c26db",
      "metadata": {
        "id": "614c26db"
      },
      "outputs": [],
      "source": [
        "data = data.drop_duplicates()\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c74ad422",
      "metadata": {
        "id": "c74ad422"
      },
      "outputs": [],
      "source": [
        "data['v1'].hist(bins=3);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95fced71",
      "metadata": {
        "id": "95fced71"
      },
      "outputs": [],
      "source": [
        "def wordcloud_vis(column):\n",
        "  mostcommon = nltk.FreqDist(data[column]).most_common(100)\n",
        "  wordcloud = WordCloud(width=1600, height=800, background_color='white').generate(str(mostcommon))\n",
        "  fig = plt.figure(figsize=(30,10), facecolor='white')\n",
        "  plt.imshow(wordcloud) #, interpolation=\"bilinear\")\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e64d870",
      "metadata": {
        "id": "9e64d870"
      },
      "outputs": [],
      "source": [
        "#Plot the word-cloud before removing stopwords, performing lemmatization\n",
        "wordcloud_vis('v2');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fb2e374",
      "metadata": {
        "scrolled": true,
        "id": "2fb2e374"
      },
      "outputs": [],
      "source": [
        "#Retain only the letters and spaces\n",
        "data['alpha_text'] = data['v2'].apply(lambda x: re.sub(r'[^a-zA-Z ]+', '', x.lower()))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dea9f8c6",
      "metadata": {
        "id": "dea9f8c6"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "data['imp_text'] = data['alpha_text'].apply(lambda x : ' '.join([word for word in x.split() if not word in set(stopwords.words('english'))]))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16f64f81",
      "metadata": {
        "id": "16f64f81"
      },
      "outputs": [],
      "source": [
        "def tokenize(data):\n",
        "  generated_token = list(data.split())\n",
        "  return generated_token\n",
        "data['token_text'] = data['imp_text'].apply(lambda x: tokenize(x))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d780581",
      "metadata": {
        "id": "3d780581"
      },
      "outputs": [],
      "source": [
        "#Perform lemmatization\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatization(list_of_words):\n",
        "  lemmatized_list = [lemmatizer.lemmatize(word) for word in list_of_words]\n",
        "  return lemmatized_list\n",
        "data['lemmatized_text'] = data['token_text'].apply(lambda x: lemmatization(x))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3bcd843",
      "metadata": {
        "id": "e3bcd843"
      },
      "outputs": [],
      "source": [
        "data['clean'] = data['lemmatized_text'].apply(lambda x: ' '.join(x))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed56a891",
      "metadata": {
        "id": "ed56a891"
      },
      "outputs": [],
      "source": [
        "#Display the word cloud after preprocessing\n",
        "wordcloud_vis('clean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad2daf16",
      "metadata": {
        "id": "ad2daf16"
      },
      "outputs": [],
      "source": [
        "#Number of unique words in spam and ham\n",
        "df1 = data.loc[data['v1'] == 'spam']\n",
        "df2 = data.loc[data['v1'] == 'ham']\n",
        "\n",
        "spam = set()\n",
        "df1['clean'].str.lower().str.split().apply(spam.update)\n",
        "print(\"Number of unique words in spam\", len(spam))\n",
        "\n",
        "ham = set()\n",
        "df2['clean'].str.lower().str.split().apply(ham.update)\n",
        "print(\"Number of unique words in ham\", len(ham))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eaedf77",
      "metadata": {
        "id": "1eaedf77"
      },
      "outputs": [],
      "source": [
        "print(\"Number of overlapping words between spam and ham: \", len(spam & ham))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c743c888",
      "metadata": {
        "id": "c743c888"
      },
      "outputs": [],
      "source": [
        "data['clean'].apply(lambda x:len(str(x).split())).max()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07b9180b",
      "metadata": {
        "id": "07b9180b"
      },
      "outputs": [],
      "source": [
        "#Prepare the data for training\n",
        "X = data['clean']\n",
        "y = data['v1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1544cef",
      "metadata": {
        "id": "e1544cef"
      },
      "outputs": [],
      "source": [
        "#Convert the class labels into integer values\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67c816eb",
      "metadata": {
        "id": "67c816eb"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fad9574",
      "metadata": {
        "id": "0fad9574"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d004961f",
      "metadata": {
        "id": "d004961f"
      },
      "outputs": [],
      "source": [
        "#Split the data into train, test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbb95fef",
      "metadata": {
        "id": "fbb95fef"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "tokenized_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_train = tf.keras.utils.pad_sequences(tokenized_train, maxlen=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a4b26a6",
      "metadata": {
        "id": "0a4b26a6"
      },
      "outputs": [],
      "source": [
        "tokenized_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = tf.keras.utils.pad_sequences(tokenized_test, maxlen=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5742bc51",
      "metadata": {
        "id": "5742bc51"
      },
      "source": [
        "## 3. Create The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c32c92d6",
      "metadata": {
        "id": "c32c92d6"
      },
      "outputs": [],
      "source": [
        "#Create a wrapper to add layers to the model\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ba4c06b",
      "metadata": {
        "id": "6ba4c06b"
      },
      "source": [
        "## 4. Add Layers (LSTM, Dense-(Hidden Layers), Output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36642118",
      "metadata": {
        "id": "36642118"
      },
      "outputs": [],
      "source": [
        "model.add(Embedding(1000, output_dim=50, input_length=100))\n",
        "model.add(LSTM(units=64 , return_sequences = True, dropout = 0.2))\n",
        "model.add(LSTM(units=32 , dropout = 0.1))\n",
        "model.add(Dense(units = 64 , activation = 'relu'))\n",
        "model.add(Dense(units = 32 , activation = 'relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111e98b3",
      "metadata": {
        "id": "111e98b3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d253b53",
      "metadata": {
        "id": "5d253b53"
      },
      "source": [
        "## 5. Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "da801047",
      "metadata": {
        "id": "da801047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "f42630d0-08dd-429f-ca31-275d4b176b83"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-11ed3973292c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dae8a6ac",
      "metadata": {
        "id": "dae8a6ac"
      },
      "source": [
        "## 6. Fit the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ab87a70",
      "metadata": {
        "id": "8ab87a70"
      },
      "outputs": [],
      "source": [
        "model.fit(X_train, y_train, batch_size=128,epochs=10,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=2)])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f318b650",
      "metadata": {
        "id": "f318b650"
      },
      "source": [
        "## 7. Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c1b28aa",
      "metadata": {
        "id": "8c1b28aa"
      },
      "outputs": [],
      "source": [
        "model.save('spam-classifier.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13c18610",
      "metadata": {
        "id": "13c18610"
      },
      "source": [
        "## 8. Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1dd67a6",
      "metadata": {
        "id": "e1dd67a6"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46e2f604",
      "metadata": {
        "id": "46e2f604"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "HTML('''<script>\n",
        "code_show_err=false; \n",
        "function code_toggle_err() {\n",
        " if (code_show_err){\n",
        " $('div.output_stderr').hide();\n",
        " } else {\n",
        " $('div.output_stderr').show();\n",
        " }\n",
        " code_show_err = !code_show_err\n",
        "} \n",
        "$( document ).ready(code_toggle_err);\n",
        "</script>\n",
        "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47d9452a",
      "metadata": {
        "id": "47d9452a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
